{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMoBa_6EJSi_"
      },
      "source": [
        "# **Application of classical algorithms for image segmentation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww8xH71__y6x"
      },
      "source": [
        "**Data download**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mwarylak/BraTS_Thesis.git"
      ],
      "metadata": {
        "id": "s7XSYOb6kN4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IIhSjsJX6qA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!kaggle datasets download -d awsaf49/brats2020-training-data\n",
        "!unzip brats2020-training-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from skimage.feature import local_binary_pattern\n",
        "from tempfile import TemporaryFile\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from joblib import dump, load\n",
        "from sklearn.multiclass import OneVsOneClassifier"
      ],
      "metadata": {
        "id": "BEDCc7j9YI6m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2trY7gN_5FL"
      },
      "source": [
        "**Loading data**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l4fGbttMJrJb"
      },
      "outputs": [],
      "source": [
        "directory = \"/content/BraTS2020_training_data/content/data\"\n",
        "h5_files = [f for f in os.listdir(directory) if f.endswith('.h5')]\n",
        "model_saving = True\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.facecolor'] = '#FFFFFF'\n",
        "plt.rcParams['text.color']       = '#474646'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iokuyE3g3C5"
      },
      "source": [
        "Method to load single images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kgB2lnTggqT5"
      },
      "outputs": [],
      "source": [
        "def sample_h5_file(dir, files, index, name = \"\"):\n",
        "    if name != \"\":\n",
        "      sample_file_path = os.path.join(dir, name)\n",
        "    else:\n",
        "      sample_file_path = os.path.join(dir, files[index])\n",
        "    with h5py.File(sample_file_path, 'r') as file:\n",
        "      image = file['image'][()].transpose(2, 0, 1)\n",
        "      mask = file['mask'][()].transpose(2, 0, 1)\n",
        "\n",
        "    print(sample_file_path)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "def test_sample(sample_file_path, index):\n",
        "    with h5py.File(sample_file_path[index], 'r') as file:\n",
        "      image = file['image'][()].transpose(2, 0, 1)\n",
        "      mask = file['mask'][()].transpose(2, 0, 1)\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQMmr8Rmg8LW"
      },
      "source": [
        "Methods for displaying MRI images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EIppCiKJJuAa"
      },
      "outputs": [],
      "source": [
        "def display_image_channels(image, title='Image Channels'):\n",
        "    channel_names = ['T1-weighted (T1)', 'T1-weighted post contrast (T1c)', 'T2-weighted (T2)', 'FLAIR']\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
        "    for idx, ax in enumerate(axes.flatten()):\n",
        "        channel_image = image[idx, :, :]\n",
        "        ax.imshow(channel_image, cmap='magma') #viridis\n",
        "        ax.axis('off')\n",
        "        ax.set_title(channel_names[idx])\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(title, fontsize=20, y=1.03)\n",
        "    plt.show()\n",
        "\n",
        "def display_mask_channels_as_rgb(mask, title='Mask Channels'):\n",
        "    channel_names = ['Necrotic (NEC)', 'Edema (ED)', 'Tumour (ET)']\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(9.75, 5))\n",
        "    for idx, ax in enumerate(axes):\n",
        "        rgb_mask = np.zeros((mask.shape[1], mask.shape[2], 3), dtype=np.uint8)\n",
        "        rgb_mask[..., idx] = mask[idx, :, :] * 255\n",
        "        ax.imshow(rgb_mask)\n",
        "        ax.axis('off')\n",
        "        ax.set_title(channel_names[idx])\n",
        "    plt.suptitle(title, fontsize=20, y=0.93)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def overlay_masks_on_image(image, mask, title='Brain MRI with Tumour Masks Overlay'):\n",
        "    t1_image = image[0, :, :]\n",
        "    t1_image_normalized = (t1_image - t1_image.min()) / (t1_image.max() - t1_image.min())\n",
        "\n",
        "    rgb_image = np.stack([t1_image_normalized] * 3, axis=-1)\n",
        "    color_mask = np.stack([mask[0, :, :], mask[1, :, :], mask[2, :, :]], axis=-1)\n",
        "    rgb_image = np.where(color_mask, color_mask, rgb_image)\n",
        "\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.imshow(rgb_image)\n",
        "    plt.title(title, fontsize=18, y=1.02)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def display_combined_mask_as_rgb(mask, title='Combined Mask as RGB'):\n",
        "    rgb_mask = np.zeros((mask.shape[1], mask.shape[2], 3), dtype=np.uint8)\n",
        "\n",
        "    rgb_mask[..., 0] = mask[0, :, :] * 255\n",
        "    rgb_mask[..., 1] = mask[1, :, :] * 255\n",
        "    rgb_mask[..., 2] = mask[2, :, :] * 255\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(rgb_mask)\n",
        "    plt.title(title, fontsize=20, y=1.02)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def display_combined_predicted_mask_as_rgb(pred_mask, title='Predicted Combined Mask'):\n",
        "    rgb_pred_mask = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3), dtype=np.uint8)\n",
        "    rgb_pred_mask[pred_mask == 1] = [255, 0, 0]\n",
        "    rgb_pred_mask[pred_mask == 2] = [0, 255, 0]\n",
        "    rgb_pred_mask[pred_mask == 3] = [0, 0, 255]\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(rgb_pred_mask)\n",
        "    plt.title(title, fontsize=20, y=1.02)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def overlay_prediction(image, pred_mask, title='Prediction Overlay'):\n",
        "    t1_image = image[0, :, :]\n",
        "    t1_image_normalized = (t1_image - t1_image.min()) / (t1_image.max() - t1_image.min())\n",
        "\n",
        "    rgb_image = np.stack([t1_image_normalized] * 3, axis=-1)\n",
        "\n",
        "    rgb_pred = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3), dtype=np.float32)\n",
        "    rgb_pred[..., 0] = (pred_mask == 1).astype(np.float32)\n",
        "    rgb_pred[..., 1] = (pred_mask == 2).astype(np.float32)\n",
        "    rgb_pred[..., 2] = (pred_mask == 3).astype(np.float32)\n",
        "\n",
        "    overlay = np.clip(rgb_image + rgb_pred * 0.5, 0, 1)\n",
        "\n",
        "    return overlay\n",
        "\n",
        "def overlay_masks(image, mask, title='Brain MRI with Tumour Masks Overlay'):\n",
        "    t1_image = image[0, :, :]\n",
        "    t1_image_normalized = (t1_image - t1_image.min()) / (t1_image.max() - t1_image.min())\n",
        "\n",
        "    rgb_image = np.stack([t1_image_normalized] * 3, axis=-1)\n",
        "    color_mask = np.stack([mask[0, :, :], mask[1, :, :], mask[2, :, :]], axis=-1)\n",
        "    rgb_image = np.where(color_mask, color_mask, rgb_image)\n",
        "\n",
        "    return rgb_image\n",
        "\n",
        "def display_side_by_side(image, pred_mask, mask, title=\"Prediction Overlay\"):\n",
        "    overlay_pred = overlay_prediction(image, pred_mask)\n",
        "    overlay_mask = overlay_masks(image, mask)\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(overlay_pred)\n",
        "    plt.title(title, fontsize=18, y=1.02)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(overlay_mask)\n",
        "    plt.title('Brain MRI with Tumour Masks Overlay', fontsize=18, y=1.02)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBV4RboucON2"
      },
      "source": [
        "**Removal of incomplete MRI scans**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CJhvzVHUVgwO"
      },
      "outputs": [],
      "source": [
        "h5_files_cleaned = []\n",
        "for i in range(len(h5_files)):\n",
        "  _, mask = sample_h5_file(directory, h5_files, i)\n",
        "  for channel in range(mask.shape[0]):\n",
        "      if mask[channel].any():\n",
        "          h5_files_cleaned.append(h5_files[i])\n",
        "          break\n",
        "\n",
        "with open(\"complete_MRI.txt\", \"w\") as file:\n",
        "    for element in h5_files_cleaned:\n",
        "        file.write(element + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJDxgqIRvsUa"
      },
      "source": [
        "**Load only full MRII scans**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q2IrRrNYbL7p"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/BraTS_Thesis/Files/h5files.txt\", \"r\") as file:\n",
        "    files = [line.strip() for line in file]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moqG8t0v9qa1"
      },
      "source": [
        "**Sample counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0VsdOeqAs2B",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def count_classes_in_masks(directory, h5_files):\n",
        "    total_non_zero_counts = [0, 0, 0]\n",
        "    samples = {0: [], 1: [], 2: []}\n",
        "\n",
        "    for i in range(len(h5_files)):\n",
        "        image, mask = sample_h5_file(directory, h5_files, i)\n",
        "\n",
        "        for channel_index in range(mask.shape[0]):\n",
        "            non_zero_count = np.count_nonzero(mask[channel_index])\n",
        "            total_non_zero_counts[channel_index] += non_zero_count\n",
        "\n",
        "            if channel_index in samples:\n",
        "                samples[channel_index].extend(np.where(mask[channel_index] > 0)[0].tolist())  # Indeksy niezerowe\n",
        "\n",
        "    for channel_index in range(len(total_non_zero_counts)):\n",
        "        print(f'Kanał {channel_index}: {total_non_zero_counts[channel_index]} wartości różne od zera')#, {total_zero_counts[channel_index]} wartości równe zeru.')\n",
        "\n",
        "count_classes_in_masks(directory, h5_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHnLk7eLK8QL"
      },
      "source": [
        "#**Segmentation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0kVQchHWVR9E"
      },
      "outputs": [],
      "source": [
        "def extract_features(image):\n",
        "    features = []\n",
        "    for channel in range(image.shape[0]):\n",
        "        channel_image = image[channel, :, :]\n",
        "        lbp = local_binary_pattern(channel_image, P=8, R=1.0, method='uniform')\n",
        "        features.append(channel_image.flatten())\n",
        "        features.append(lbp.flatten())\n",
        "    return np.array(features).T\n",
        "\n",
        "def train_model(model, images, directory, batch_size, norm_type = ''):\n",
        "    print(f'Model: {model}\\nNormalization: {norm_type}')\n",
        "    feature_file = TemporaryFile()\n",
        "    label_file = TemporaryFile()\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    files = images\n",
        "    batch_size = batch_size\n",
        "\n",
        "    for batch_start in range(0, len(files), batch_size):\n",
        "        print(f'Batch: {batch_start}')\n",
        "        batch_files = files[batch_start:batch_start + batch_size]\n",
        "        batch_features = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for file_name in batch_files:\n",
        "            sample_file_path = os.path.join(directory, file_name)\n",
        "            with h5py.File(sample_file_path, 'r') as file:\n",
        "                image = file['image'][()].transpose(2, 0, 1)\n",
        "                if 'mask' not in file:\n",
        "                    print(f\"No mask found for {file_name}, skipping.\")\n",
        "                    continue\n",
        "                mask = file['mask'][()].transpose(2, 0, 1)\n",
        "\n",
        "                if norm_type == 'min-max':\n",
        "                  for i in range(image.shape[0]):\n",
        "                    min_val = np.min(image[i])\n",
        "                    image[i] = image[i] - min_val\n",
        "                    max_val = np.max(image[i]) + 1e-4\n",
        "                    image[i] = image[i] / max_val\n",
        "\n",
        "                elif norm_type == 'z_score':\n",
        "                  mean = image.mean()\n",
        "                  std = image.std()\n",
        "                  image = (image - mean) / std\n",
        "\n",
        "                elif norm_type == 'percent':\n",
        "                  p2, p98 = np.percentile(image, (2, 98))\n",
        "                  image_clipped = np.clip(image, p2, p98)\n",
        "                  image = (image_clipped - p2) / (p98 - p2)\n",
        "\n",
        "                else:\n",
        "                  pass\n",
        "\n",
        "                nec_mask = mask[0, :, :]\n",
        "                ed_mask = mask[1, :, :]\n",
        "                et_mask = mask[2, :, :]\n",
        "\n",
        "                multi_class_mask = np.zeros_like(nec_mask)\n",
        "                multi_class_mask[nec_mask > 0] = 1\n",
        "                multi_class_mask[ed_mask > 0] = 2\n",
        "                multi_class_mask[et_mask > 0] = 3\n",
        "\n",
        "                features = extract_features(image)\n",
        "                labels = multi_class_mask.flatten()\n",
        "                batch_features.append(features)\n",
        "                batch_labels.append(labels)\n",
        "\n",
        "        if batch_features:\n",
        "            batch_features = np.vstack(batch_features)\n",
        "            batch_labels = np.hstack(batch_labels)\n",
        "\n",
        "            if batch_start == 0:\n",
        "                scaler.fit(batch_features)\n",
        "            batch_features_scaled = scaler.transform(batch_features)\n",
        "\n",
        "            feature_file.seek(0, os.SEEK_END)\n",
        "            np.save(feature_file, batch_features_scaled)\n",
        "\n",
        "            label_file.seek(0, os.SEEK_END)\n",
        "            np.save(label_file, batch_labels)\n",
        "\n",
        "    feature_file.seek(0)\n",
        "    label_file.seek(0)\n",
        "\n",
        "    try:\n",
        "        all_features = np.load(feature_file, allow_pickle=True)\n",
        "        all_labels = np.load(label_file, allow_pickle=True)\n",
        "        print(f\"Read {all_features.shape} features and {all_labels.shape} labels.\")\n",
        "    except Exception as e:\n",
        "        print(\"There was a problem while loading the data:\", e)\n",
        "\n",
        "    print(f\"Number of samples: {len(all_features)}, Number of labels: {len(all_labels)}\")\n",
        "    if len(all_features) == 0 or len(all_labels) == 0:\n",
        "        raise ValueError(\"No data to split. Check if the images contain masks.\")\n",
        "\n",
        "    print(\"Unique classes in labels:\", np.unique(all_labels))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(all_features, all_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    multimodel = model\n",
        "    multimodel.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = multimodel.predict(X_test)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    return y_pred, y_test, multimodel\n",
        "\n",
        "def save_model(model, filename='model.joblib'):\n",
        "  dump(model, filename)\n",
        "\n",
        "def load_model(filename):\n",
        "  return load(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test image to check the results after training"
      ],
      "metadata": {
        "id": "I6K6VQeVZubX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0NXkg1zGwoj",
        "outputId": "54723d5e-48e1-44db-8173-c033a349d543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BraTS2020_training_data/content/data/volume_324_slice_57.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/skimage/feature/texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "image, mask = sample_h5_file(directory, files, 105)\n",
        "\n",
        "nec_mask = mask[0, :, :]\n",
        "ed_mask = mask[1, :, :]\n",
        "et_mask = mask[2, :, :]\n",
        "\n",
        "multi_class_mask = np.zeros_like(nec_mask)\n",
        "multi_class_mask[nec_mask > 0] = 1\n",
        "multi_class_mask[ed_mask > 0] = 2\n",
        "multi_class_mask[et_mask > 0] = 3\n",
        "\n",
        "features = extract_features(image)\n",
        "labels = multi_class_mask.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine"
      ],
      "metadata": {
        "id": "avDK4wrvabYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "EmHBUAVvlOmG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZBpmdH7SV9x"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = OneVsOneClassifier(LinearSVC(random_state=42))\n",
        "y_svm_pred, y_svm_test, svm_model = train_model(model, files, directory, batch_size=200, norm_type='min-max')\n",
        "\n",
        "features_scaled = scaler.transform(features)\n",
        "\n",
        "svm_pred_mask = svm_model.predict(features_scaled)\n",
        "svm_pred_mask_image = svm_pred_mask.reshape(multi_class_mask.shape)\n",
        "\n",
        "if model_saving:\n",
        "  save_model(svm_model, '/content/BraTS_Thesis/models_weights/svm_model.joblib')\n",
        "\n",
        "display_side_by_side(image, svm_pred_mask_image, mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "nl8BE-g5lbjL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwtiZxO5ErEm"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/BraTS_Thesis/Files/Test_Samples'\n",
        "test_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "\n",
        "index = random.randint(0, 149)\n",
        "image, mask = test_sample(test_files, index=index)\n",
        "\n",
        "nec_mask = mask[0, :, :]\n",
        "ed_mask = mask[1, :, :]\n",
        "et_mask = mask[2, :, :]\n",
        "\n",
        "multi_class_mask = np.zeros_like(nec_mask)\n",
        "multi_class_mask[nec_mask > 0] = 1\n",
        "multi_class_mask[ed_mask > 0] = 2\n",
        "multi_class_mask[et_mask > 0] = 3\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features = extract_features(image)\n",
        "labels = multi_class_mask.flatten()\n",
        "\n",
        "X_train, X_test, _, _ = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "_ = scaler.fit_transform(X_train)\n",
        "_ = scaler.transform(X_test)\n",
        "features_scaled = scaler.transform(features)\n",
        "\n",
        "svm_model = load_model('/content/BraTS_Thesis/models_weights/svm_model.joblib')\n",
        "\n",
        "svm_pred_mask = svm_model.predict(features_scaled)\n",
        "svm_pred_mask_image = svm_pred_mask.reshape(multi_class_mask.shape)\n",
        "\n",
        "display_side_by_side(image, svm_pred_mask_image, mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii4Ooy7bWpAe"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "jvBG_wO3lxUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtjmGJIS5xjf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "y_rf_pred, y_rf_test, rf_model = train_model(model, files, directory, batch_size=200, norm_type = '')\n",
        "\n",
        "features_scaled = scaler.transform(features)\n",
        "\n",
        "rf_pred_mask = rf_model.predict(features_scaled)\n",
        "rf_pred_mask_image = rf_pred_mask.reshape(multi_class_mask.shape)\n",
        "\n",
        "if model_saving:\n",
        "  save_model(rf_model, '/content/BraTS_Thesis/models_weights/random_forest.joblib')\n",
        "\n",
        "display_side_by_side(image, rf_pred_mask_image, mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "vvWs1pS7qs4i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6lXp2G7BglU"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/BraTS_Thesis/Files/Test_Samples'\n",
        "test_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "\n",
        "index = random.randint(0, 149)\n",
        "image, mask = test_sample(test_files, index=index)\n",
        "\n",
        "nec_mask = mask[0, :, :]\n",
        "ed_mask = mask[1, :, :]\n",
        "et_mask = mask[2, :, :]\n",
        "\n",
        "multi_class_mask = np.zeros_like(nec_mask)\n",
        "multi_class_mask[nec_mask > 0] = 1\n",
        "multi_class_mask[ed_mask > 0] = 2\n",
        "multi_class_mask[et_mask > 0] = 3\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features = extract_features(image)\n",
        "labels = multi_class_mask.flatten()\n",
        "\n",
        "X_train, X_test, _, _ = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "_ = scaler.fit_transform(X_train)\n",
        "_ = scaler.transform(X_test)\n",
        "features_scaled = scaler.transform(features)\n",
        "\n",
        "rf_model = load_model('/content/BraTS_Thesis/models_weights/random_forest.joblib')\n",
        "\n",
        "rf_pred_mask = rf_model.predict(features_scaled)\n",
        "rf_pred_mask_image = rf_pred_mask.reshape(multi_class_mask.shape)\n",
        "\n",
        "display_side_by_side(image, rf_pred_mask_image, mask)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}